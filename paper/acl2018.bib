
@article{LampleNeuralArchitecturesNamed2016,
  title = {Neural {{Architectures}} for {{Named Entity Recognition}}},
  language = {en},
  author = {Lample, Guillaume and Ballesteros, Miguel and Subramanian, Sandeep and Kawakami, Kazuya and Dyer, Chris},
  month = mar,
  year = {2016},
  file = {/Users/andrewlarimer/Zotero/storage/HZUHD56H/Lample et al. - 2016 - Neural Architectures for Named Entity Recognition.pdf;/Users/andrewlarimer/Zotero/storage/H9AKRWG3/1603.html}
}

@inproceedings{NivreIncrementalityDeterministicDependency2004,
  address = {Stroudsburg, PA, USA},
  series = {IncrementParsing '04},
  title = {Incrementality in {{Deterministic Dependency Parsing}}},
  abstract = {Deterministic dependency parsing is a robust and efficient approach to syntactic parsing of unrestricted natural language text. In this paper, we analyze its potential for incremental processing and conclude that strict incrementality is not achievable within this framework. However, we also show that it is possible to minimize the number of structures that require non-incremental processing by choosing an optimal parsing algorithm. This claim is substantiated with experimental evidence showing that the algorithm achieves incremental parsing for 68.9\% of the input when tested on a random sample of Swedish text. When restricted to sentences that are accepted by the parser, the degree of incrementality increases to 87.9\%.},
  booktitle = {Proceedings of the {{Workshop}} on {{Incremental Parsing}}: {{Bringing Engineering}} and {{Cognition Together}}},
  publisher = {{Association for Computational Linguistics}},
  author = {Nivre, Joakim},
  year = {2004},
  pages = {50--57},
  file = {/Users/andrewlarimer/Zotero/storage/XJQ2FEWS/Nivre - 2004 - Incrementality in Deterministic Dependency Parsing.pdf}
}

@article{DyerTransitionBasedDependencyParsing2015,
  title = {Transition-{{Based Dependency Parsing}} with {{Stack Long Short}}-{{Term Memory}}},
  language = {en},
  author = {Dyer, Chris and Ballesteros, Miguel and Ling, Wang and Matthews, Austin and Smith, Noah A.},
  month = may,
  year = {2015},
  file = {/Users/andrewlarimer/Zotero/storage/XBFGZWHX/Dyer et al. - 2015 - Transition-Based Dependency Parsing with Stack Lon.pdf;/Users/andrewlarimer/Zotero/storage/NRVLJHB6/1505.html}
}

@misc{Interleavingontologybasedreasoning,
  title = {Interleaving Ontology-Based Reasoning and {{Natural Language Processing}} for Character Identification in Folktales - {{IEEE Conference Publication}}},
  howpublished = {https://ieeexplore.ieee.org/document/6936982},
  file = {/Users/andrewlarimer/Zotero/storage/C8IHPESQ/6936982.html}
}

@inproceedings{SuciuInterleavingontologybasedreasoning2014,
  title = {Interleaving Ontology-Based Reasoning and {{Natural Language Processing}} for Character Identification in Folktales},
  doi = {10.1109/ICCP.2014.6936982},
  abstract = {We propose a system for identifying literary characters from folktales. The process of extracting characters from free texts is guided by an ontology that encodes the knowledge of the folktale domain. We present how the ontology works with Natural Language Processing in GATE to increase the accuracy of character recognition. We validated the solution against various folktales.},
  booktitle = {2014 {{IEEE}} 10th {{International Conference}} on {{Intelligent Computer Communication}} and {{Processing}} ({{ICCP}})},
  author = {Suciu, D. and Groza, A.},
  month = sep,
  year = {2014},
  keywords = {character extraction,character recognition,characters identification,folktale,folktales,free text,GATE,humanities,inference mechanisms,knowledge encoding,literary character identification,Logic gates,Measurement,natural language processing,Natural language processing,ontologies,Ontologies,ontologies (artificial intelligence),ontology-based reasoning,Pipelines,Semantics,Syntactics,text analysis},
  pages = {67-74},
  file = {/Users/andrewlarimer/Zotero/storage/667K3GPG/6936982.html}
}

@article{HuReadVerifyMachine2018,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1808.05759},
  primaryClass = {cs},
  title = {Read + {{Verify}}: {{Machine Reading Comprehension}} with {{Unanswerable Questions}}},
  shorttitle = {Read + {{Verify}}},
  abstract = {Machine reading comprehension with unanswerable questions aims to abstain from answering when no answer can be inferred. In addition to extract answers, previous works usually predict an additional "no-answer" probability to detect unanswerable cases. However, they fail to validate the answerability of the question by verifying the legitimacy of the predicted answer. To address this problem, we propose a novel read-then-verify system, which not only utilizes a neural reader to extract candidate answers and produce no-answer probabilities, but also leverages an answer verifier to decide whether the predicted answer is entailed by the input snippets. Moreover, we introduce two auxiliary losses to help the reader better handle answer extraction as well as no-answer detection, and investigate three different architectures for the answer verifier. Our experiments on the SQuAD 2.0 dataset show that our system achieves a score of 74.2 F1 on the test set, achieving state-of-the-art results at the time of submission (Aug. 28th, 2018).},
  journal = {arXiv:1808.05759 [cs]},
  author = {Hu, Minghao and Wei, Furu and Peng, Yuxing and Huang, Zhen and Yang, Nan and Li, Dongsheng},
  month = aug,
  year = {2018},
  keywords = {Computer Science - Computation and Language},
  file = {/Users/andrewlarimer/Zotero/storage/SVC8UWU8/Hu et al. - 2018 - Read + Verify Machine Reading Comprehension with .pdf;/Users/andrewlarimer/Zotero/storage/VJJ4E3ZQ/1808.html}
}

@article{RajpurkarKnowWhatYou2018,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1806.03822},
  primaryClass = {cs},
  title = {Know {{What You Don}}'t {{Know}}: {{Unanswerable Questions}} for {{SQuAD}}},
  shorttitle = {Know {{What You Don}}'t {{Know}}},
  abstract = {Extractive reading comprehension systems can often locate the correct answer to a question in a context document, but they also tend to make unreliable guesses on questions for which the correct answer is not stated in the context. Existing datasets either focus exclusively on answerable questions, or use automatically generated unanswerable questions that are easy to identify. To address these weaknesses, we present SQuAD 2.0, the latest version of the Stanford Question Answering Dataset (SQuAD). SQuAD 2.0 combines existing SQuAD data with over 50,000 unanswerable questions written adversarially by crowdworkers to look similar to answerable ones. To do well on SQuAD 2.0, systems must not only answer questions when possible, but also determine when no answer is supported by the paragraph and abstain from answering. SQuAD 2.0 is a challenging natural language understanding task for existing models: a strong neural system that gets 86\% F1 on SQuAD 1.1 achieves only 66\% F1 on SQuAD 2.0.},
  journal = {arXiv:1806.03822 [cs]},
  author = {Rajpurkar, Pranav and Jia, Robin and Liang, Percy},
  month = jun,
  year = {2018},
  keywords = {Computer Science - Computation and Language},
  file = {/Users/andrewlarimer/Zotero/storage/YQCBFJLL/Rajpurkar et al. - 2018 - Know What You Don't Know Unanswerable Questions f.pdf;/Users/andrewlarimer/Zotero/storage/5ZM95SCB/1806.html}
}

@article{spacy2,
   author = {Honnibal, Matthew AND Montani, Ines},
   TITLE = {spaCy 2: Natural language understanding with Bloom embeddings, convolutional neural networks and incremental parsing},
   year = {2017},
   journal = {To appear}
}
