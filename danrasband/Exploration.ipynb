{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project: Exploration\n",
    "\n",
    "* Authors: Andrew Larimer and Dan Rasband\n",
    "\n",
    "The objective of this notebook is to experiment with fictional texts to determine the associations between characters and possibly even summarize their traits in some way. The plan is to first use word counts, part-of-speech tagging, and auto-generated syntax trees to determine the graph of associations, then to use the above to determine adjectives that describe each character.\n",
    "\n",
    "Texts were obtained from http://www.glozman.com/textpages.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/ubuntu/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/ubuntu/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "# File handling\n",
    "import io\n",
    "\n",
    "# Data Cleaning\n",
    "import re\n",
    "\n",
    "# Utils\n",
    "from importlib import reload\n",
    "\n",
    "# NLTK Stuff\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "from nltk.data import load as nltk_load\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize.treebank import TreebankWordTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-rw-r-- 1 ubuntu ubuntu 439K Nov 14 08:27 data/harry_potter_1_sorcerer_s_stone.txt\r\n"
     ]
    }
   ],
   "source": [
    "# Harry Potter: Book 1\n",
    "! ls -lah data/harry_potter_1_sorcerer_s_stone.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mr. and Mrs. Dursley, of number four, Privet Drive, were proud to say that they were perfectly normal, thank you very much. They were the last people you'd expect to be involved in anything strange or mysterious, because they just didn't hold with such nonsense. \n",
      "\n",
      "Mr. Dursley was the director of a firm called Grunnings, which made drills. He was a big, beefy man with hardly any neck, although he did have a very large mustache. Mrs. Dursley was thin and blonde and had nearly twice the usual amoun\n",
      "\n",
      "...\n",
      "\n",
      "p, boy, we haven't got all day.\" He walked away. \n",
      "\n",
      "Harry hung back for a last word with Ron and Hermione. \n",
      "\n",
      "\"See you over the summer, then.\" \n",
      "\n",
      "\"Hope you have -- er -- a good holiday,\" said Hermione, looking uncertainly after Uncle Vernon, shocked that anyone could be so unpleasant. \n",
      "\n",
      "\"Oh, I will,\" said Harry, and they were surprised at the grin that was spreading over his face. \"They don't know we're not allowed to use magic at home. I'm going to have a lot of fun with Dudley this summer....\" \n",
      "\n",
      "\n",
      "Length: 441419\n"
     ]
    }
   ],
   "source": [
    "with open('data/harry_potter_1_sorcerer_s_stone.txt', mode='r', encoding='utf-8') as text_file:\n",
    "    text = text_file.read()\n",
    "    text = re.sub(r'(?:[A-Z]{2,}\\s+)', '', text)\n",
    "    text = text[40:]\n",
    "    print(text[0:500])\n",
    "    print('\\n...\\n')\n",
    "    print(text[-500:])\n",
    "    print('Length: {}'.format(len(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndred and thirteen, if you could call it emptying, taking out that grubby little package. had that been what the thieves were looking for? as harry and ron walked back to the castle for dinner, their pockets weighed down with rock cakes they'd been too polite to refuse, harry thought that none of the lessons he'd had so far had given him as much to think about as tea with hagrid. had hagrid collected that package just in time? where was it now? and did hagrid know something about snape that he d\n"
     ]
    }
   ],
   "source": [
    "cleaned_text = text.lower()\n",
    "cleaned_text = re.sub(r'\\s+', ' ', cleaned_text)\n",
    "print(cleaned_text[200000:200500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mr.', 'and', 'mrs.', 'dursley', ',', 'of', 'number', 'four', ',', 'privet', 'drive', ',', 'were', 'proud', 'to', 'say', 'that', 'they', 'were', 'perfectly', 'normal', ',', 'thank', 'you', 'very', 'much', '.', 'they', 'were', 'the', 'last', 'people', 'you', \"'d\", 'expect', 'to', 'be', 'involved', 'in', 'anything', 'strange', 'or', 'mysterious', ',', 'because', 'they', 'just', 'did', \"n't\", 'hold', 'with', 'such', 'nonsense', '.', 'mr.', 'dursley', 'was', 'the', 'director', 'of', 'a', 'firm', 'called', 'grunnings', ',', 'which', 'made', 'drills', '.', 'he', 'was', 'a', 'big', ',', 'beefy', 'man', 'with', 'hardly', 'any', 'neck', ',', 'although', 'he', 'did', 'have', 'a', 'very', 'large', 'mustache', '.', 'mrs.', 'dursley', 'was', 'thin', 'and', 'blonde', 'and', 'had', 'nearly', 'twice']\n"
     ]
    }
   ],
   "source": [
    "tokens = word_tokenize(cleaned_text)\n",
    "print(tokens[0:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mr. and Mrs. Dursley, of number four, Privet Drive, were proud to say that they were perfectly normal, thank you very much.\n",
      "\n",
      "They were the last people you'd expect to be involved in anything strange or mysterious, because they just didn't hold with such nonsense.\n",
      "\n",
      "Mr. Dursley was the director of a firm called Grunnings, which made drills.\n"
     ]
    }
   ],
   "source": [
    "def sentence_tokenize(text):\n",
    "    \"\"\"\n",
    "    Return a sentence-tokenized copy of *text*,\n",
    "    using NLTK's recommended sentence tokenizer\n",
    "    (currently :class:`.PunktSentenceTokenizer`\n",
    "    for the specified language).\n",
    "\n",
    "    :param text: text to split into sentences\n",
    "    :param language: the model name in the Punkt corpus\n",
    "    \"\"\"\n",
    "    tokenizer = nltk_load('../nltk_data/tokenizers/punkt/english.pickle')\n",
    "    return tokenizer.tokenize(text)\n",
    "\n",
    "\n",
    "sentences = sentence_tokenize(re.sub(r'\\s+', ' ', text))\n",
    "print('\\n\\n'.join(sentences[:3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Mr.', 'NNP'),\n",
       " ('and', 'CC'),\n",
       " ('Mrs.', 'NNP'),\n",
       " ('Dursley', 'NNP'),\n",
       " (',', ','),\n",
       " ('of', 'IN'),\n",
       " ('number', 'NN'),\n",
       " ('four', 'CD'),\n",
       " (',', ','),\n",
       " ('Privet', 'NNP'),\n",
       " ('Drive', 'NNP'),\n",
       " (',', ','),\n",
       " ('were', 'VBD'),\n",
       " ('proud', 'JJ'),\n",
       " ('to', 'TO'),\n",
       " ('say', 'VB'),\n",
       " ('that', 'IN'),\n",
       " ('they', 'PRP'),\n",
       " ('were', 'VBD'),\n",
       " ('perfectly', 'RB'),\n",
       " ('normal', 'JJ'),\n",
       " (',', ','),\n",
       " ('thank', 'NN'),\n",
       " ('you', 'PRP'),\n",
       " ('very', 'RB'),\n",
       " ('much', 'RB'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_tokenizer = TreebankWordTokenizer()\n",
    "nltk.pos_tag(tree_tokenizer.tokenize(sentences[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers import core_nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "server = core_nlp.CoreNLPServer(\n",
    "    path_to_jar='/mnt/bigdrive/ubuntu/stanford-corenlp-full-2018-10-05/stanford-corenlp-3.9.2.jar',\n",
    "    path_to_models_jar='/mnt/bigdrive/ubuntu/stanford-english-corenlp-2018-10-05-models.jar',\n",
    "    port=9000)\n",
    "server.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = core_nlp.CoreNLPDependencyParser(tagtype='ner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mr. and Mrs. Dursley, of number four, Privet Drive, were proud to say that they were perfectly normal, thank you very much.'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "parse, = parser.raw_parse(sentences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mr.\tNNP\t4\tcompound\n",
      "and\tCC\t1\tcc\n",
      "Mrs.\tNNP\t1\tconj\n",
      "Dursley\tNNP\t14\tnsubj\n",
      ",\t,\t4\tpunct\n",
      "of\tIN\t7\tcase\n",
      "number\tNN\t4\tnmod\n",
      "four\tCD\t7\tnummod\n",
      ",\t,\t4\tpunct\n",
      "Privet\tNNP\t11\tcompound\n",
      "Drive\tNNP\t4\tappos\n",
      ",\t,\t4\tpunct\n",
      "were\tVBD\t14\tcop\n",
      "proud\tJJ\t0\tROOT\n",
      "to\tTO\t16\tmark\n",
      "say\tVB\t14\txcomp\n",
      "that\tIN\t21\tmark\n",
      "they\tPRP\t21\tnsubj\n",
      "were\tVBD\t21\tcop\n",
      "perfectly\tRB\t21\tadvmod\n",
      "normal\tJJ\t16\tccomp\n",
      ",\t,\t14\tpunct\n",
      "thank\tVB\t14\tdep\n",
      "you\tPRP\t23\tdobj\n",
      "very\tRB\t26\tadvmod\n",
      "much\tRB\t23\tadvmod\n",
      ".\t.\t14\tpunct\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(parse.to_conll(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(proud\n",
      "  (Dursley (Mr. and Mrs.) , (number of four) , (Drive Privet) ,)\n",
      "  were\n",
      "  (say to (normal that they were perfectly))\n",
      "  ,\n",
      "  (thank you (much very))\n",
      "  .)\n"
     ]
    }
   ],
   "source": [
    "print(parse.tree())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('proud', 'JJ') nsubj ('Dursley', 'NNP')\n",
      "('Dursley', 'NNP') compound ('Mr.', 'NNP')\n",
      "('Mr.', 'NNP') cc ('and', 'CC')\n",
      "('Mr.', 'NNP') conj ('Mrs.', 'NNP')\n",
      "('Dursley', 'NNP') punct (',', ',')\n",
      "('Dursley', 'NNP') nmod ('number', 'NN')\n",
      "('number', 'NN') case ('of', 'IN')\n",
      "('number', 'NN') nummod ('four', 'CD')\n",
      "('Dursley', 'NNP') punct (',', ',')\n",
      "('Dursley', 'NNP') appos ('Drive', 'NNP')\n",
      "('Drive', 'NNP') compound ('Privet', 'NNP')\n",
      "('Dursley', 'NNP') punct (',', ',')\n",
      "('proud', 'JJ') cop ('were', 'VBD')\n",
      "('proud', 'JJ') xcomp ('say', 'VB')\n",
      "('say', 'VB') mark ('to', 'TO')\n",
      "('say', 'VB') ccomp ('normal', 'JJ')\n",
      "('normal', 'JJ') mark ('that', 'IN')\n",
      "('normal', 'JJ') nsubj ('they', 'PRP')\n",
      "('normal', 'JJ') cop ('were', 'VBD')\n",
      "('normal', 'JJ') advmod ('perfectly', 'RB')\n",
      "('proud', 'JJ') punct (',', ',')\n",
      "('proud', 'JJ') dep ('thank', 'VB')\n",
      "('thank', 'VB') dobj ('you', 'PRP')\n",
      "('thank', 'VB') advmod ('much', 'RB')\n",
      "('much', 'RB') advmod ('very', 'RB')\n",
      "('proud', 'JJ') punct ('.', '.')\n"
     ]
    }
   ],
   "source": [
    "for governor, dep, dependent in parse.triples():\n",
    "    print(governor, dep, dependent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
